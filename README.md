<div align="center">
  <img src="https://github.com/user-attachments/assets/59be3433-6983-4e43-980c-ab2996ff84c2" alt="Halo Logo" width="150px">
  <h1>Virtual Well-being Companion</h1>
</div>

---
![halo](https://github.com/user-attachments/assets/0a2939b4-c98d-4ca3-bb05-c53d7441c466)

![darkmode](https://github.com/user-attachments/assets/8a4e1bff-e289-4127-bc86-a7af0d6e244e)


---

![home](https://github.com/user-attachments/assets/a8ea444e-7b5a-4745-a054-4e1c12077751)
![llm talk](https://github.com/user-attachments/assets/55fac168-7bb5-4664-8133-55a77bed671c)


## Overview!


**Halo** is a virtual mental wellbeing assistant designed to help users reflect on their emotions and daily experiences. Built around Hume's [Empathic Voice Interface](https://hume.docs.buildwithfern.com/docs/empathic-voice-interface-evi/overview) using the Hume React SDK, Halo uses emotionally intelligent AI to analyze conversations and provide meaningful insights.

This project is built on **Next.js App Router** and integrates various advanced technologies, including the **GEMINI API** for conversation history analysis and **Google Echo** to gather and summarize emotional data. By focusing on users' mental health, Halo offers an empathetic companion that checks in, interacts, and assists in maintaining a positive emotional state.

The UI/UX design is dynamic, featuring **dark mode and light mode** options to cater to user preferences and enhance readability in different environments. This ensures a visually intuitive interface for users to track their emotional history and gain insights through visualizations.

## Features

- **Hume AI Integration**: Empathic Voice Interface (EVI) for emotionally intelligent conversations.
- **GEMINI API**: Collects and summarizes user conversation history to offer personalized insights.
- **Emotional Data Visualization**: Hume AI's emotional insights are visualized in a dynamic, easy-to-navigate dashboard to help users track and reflect on their mental health.
- **User Recognition and Personalized Care**: Uses camera and motion detection to identify users and initiate conversations.
- **Music Recommendations**: Integrates with the Spotify API to suggest music based on the user’s emotional state.
- **Dynamic UI/UX with Dark and Light Mode**: Offers both dark mode and light mode options, creating a visually appealing and responsive interface that enhances user experience.
  
## Technologies Used

- **Hume AI**: Empathic Voice Interface and emotional data insights.
- **Next.js**: Server-side rendering and efficient routing.
- **GEMINI API**: Conversation history analysis and summarization.
- **Spotify API**: Emotion-based music recommendations.
- **Computer Vision**: Used for user recognition and motion detection.
- **Dynamic UI/UX Design with Dark and Light Mode**: Created with React and TypeScript to offer an engaging and intuitive user experience that adapts to user preferences.

## Deployment

Deploy this project with Vercel using the button below:

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fhumeai%2Fhume-evi-next-js-starter&env=HUME_API_KEY,HUME_SECRET_KEY)

### Steps to Deploy:

1. **Fork the repository**: Create your Git repository for Halo.
2. **Set up environment variables**: You’ll need your Hume API key and Client Secret key, which can be generated by logging into the [Hume portal](https://beta.hume.ai/settings/keys).
3. **Deploy on Vercel**: Follow the instructions provided by Vercel to complete the deployment.

## How to Contribute

If you want to contribute or collaborate on Halo, please submit pull requests or create issues in the repository. We welcome all kinds of suggestions and improvements!

## Support

For questions or assistance with using Hume AI or implementing Halo, join us on [Hume's Discord community](https://link.hume.ai/discord).
